% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
  twocolumn,
  a4paper]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
    \setmainfont[]{Latin Modern Roman}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{microtype}

\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  filecolor=magenta,
  urlcolor=cyan,
}

\renewcommand{\vec}[1]{\mathbf{#1}}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Neural Network Training Dynamics on MNIST: A Comprehensive Analysis},
  pdfauthor={Author One; Author Two},
  pdfkeywords={neural networks, MNIST, deep learning, training
dynamics, optimization},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Neural Network Training Dynamics on MNIST: A Comprehensive
Analysis}
\author{Author One \and Author Two}
\date{2025-04-15}

\begin{document}
\maketitle
\begin{abstract}
We present a comprehensive analysis of neural network training dynamics
on the MNIST dataset. Our work systematically investigates the impact of
various architectural choices, optimization strategies, and
regularization techniques on model performance, convergence behavior,
and generalization capabilities. Through extensive experimentation, we
demonstrate that careful consideration of hyperparameters leads to
significant improvements in model accuracy and robustness. We also
provide visual insights into the learning process, examining weight
distributions, activation patterns, and representation spaces across
training epochs. Our findings contribute to a deeper understanding of
the fundamental principles governing neural network learning on image
classification tasks.
\end{abstract}


\section{Introduction}\label{introduction}

The MNIST dataset of handwritten digits has become a canonical benchmark
for evaluating machine learning algorithms since its introduction by
LeCun et al. {[}1{]}. Despite its apparent simplicity, the dataset
continues to provide valuable insights into the behavior of learning
algorithms, particularly neural networks. In this paper, we conduct a
thorough investigation of neural network training dynamics on MNIST,
focusing on several key aspects:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The progression of weight distributions and activation patterns during
  training
\item
  The impact of network architecture on learning efficiency and final
  performance
\item
  The effectiveness of various optimization algorithms and learning rate
  schedules
\item
  The influence of regularization techniques on generalization
  performance
\end{enumerate}

Our analysis combines quantitative metrics with qualitative
visualizations to provide a comprehensive understanding of the learning
process. We believe this work contributes to the field by systematically
documenting patterns in neural network training that may inform both
theoretical research and practical applications.

\section{Related Work}\label{related-work}

Neural networks have a rich history dating back to the perceptron model
of Rosenblatt {[}2{]}. The backpropagation algorithm, formalized by
Rumelhart et al. {[}3{]}, enabled efficient training of multi-layer
networks. The MNIST dataset itself was introduced as a benchmark for
comparing machine learning methods for digit recognition {[}1{]}.

More recent work has explored visualization techniques for understanding
neural network internals {[}4{]} and mathematical frameworks for
analyzing optimization dynamics {[}5{]}. Our work builds upon these
foundations by providing a unified analysis that combines multiple
perspectives.

\section{Methods}\label{methods}

\subsection{Dataset}\label{dataset}

The MNIST dataset consists of 70,000 grayscale images of handwritten
digits (0-9), with a standard split of 60,000 training images and 10,000
test images. Each image is 28×28 pixels, resulting in 784 features per
sample when flattened. We apply standard preprocessing by normalizing
pixel values to the range {[}0,1{]}.

\subsection{Model Architecture}\label{model-architecture}

We experiment with a family of convolutional neural networks (CNNs) of
varying depths and widths. Our baseline architecture consists of:

\begin{itemize}
\tightlist
\item
  Two convolutional layers with 32 and 64 filters respectively, each
  followed by 2×2 max pooling
\item
  A fully connected layer with 128 units and ReLU activation
\item
  A softmax output layer with 10 units (one per digit class)
\end{itemize}

For regularization, we employ dropout with probability 0.5 on the fully
connected layer.

\subsection{Training Procedure}\label{training-procedure}

Models are trained using mini-batch stochastic gradient descent (SGD)
with a batch size of 128. We evaluate several optimization algorithms
including vanilla SGD, SGD with momentum, RMSProp, and Adam. Learning
rates are initially set to 0.01 for SGD and 0.001 for Adam, with decay
schedules applied as training progresses.

Training continues for 20 epochs, with model checkpoints saved at each
epoch for subsequent analysis.

\section{Results}\label{results}

\subsection{Performance Metrics}\label{performance-metrics}

Our best model achieves 99.3\% accuracy on the test set, which is
comparable to state-of-the-art results for similarly sized networks on
MNIST. Figure 1 shows the progression of training and validation
accuracy across epochs for different optimization algorithms.

\textsubscript{Source:
\href{https://Jing-yilin.github.io/mnist/index.qmd.html}{Article
Notebook}}

\subsection{Weight Distribution
Analysis}\label{weight-distribution-analysis}

We track the distribution of weights in each layer throughout training.
Figure 2 shows how these distributions evolve from their initial
Gaussian form to more complex multimodal distributions as learning
progresses.

\textsubscript{Source:
\href{https://Jing-yilin.github.io/mnist/index.qmd.html}{Article
Notebook}}

\textsubscript{Source:
\href{https://Jing-yilin.github.io/mnist/index.qmd.html}{Article
Notebook}}

\subsection{Activation Pattern
Analysis}\label{activation-pattern-analysis}

By visualizing the activation patterns for different input samples, we
gain insights into the representations learned by the network. Figure 3
presents t-SNE projections of the activations in the penultimate layer,
showing clear separation of digit classes.

\section{Discussion}\label{discussion}

Our results demonstrate several key principles in neural network
training:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Early layers tend to learn general features (e.g., edge detectors)
  while later layers specialize in digit-specific features
\item
  The Adam optimizer consistently outperforms SGD in terms of
  convergence speed, though final accuracies are comparable
\item
  Dropout significantly improves generalization, particularly for deeper
  architectures
\item
  Weight distributions shift from initial Gaussian distributions toward
  more complex, task-specific distributions
\end{enumerate}

These observations align with the broader literature on deep learning
while providing specific insights into the MNIST use case.

\section{Conclusion}\label{conclusion}

This comprehensive analysis of neural network training dynamics on MNIST
provides valuable insights into the learning process. Our findings
illustrate how architectural choices, optimization strategies, and
regularization techniques interact to determine model performance and
training behavior.

Future work could extend this analysis to more complex datasets and
architectures, potentially uncovering whether the patterns observed here
generalize to more challenging domains.

\section{References}\label{references}

\textsubscript{Source:
\href{https://Jing-yilin.github.io/mnist/index.qmd.html}{Article
Notebook}}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{0}
\bibitem[\citeproctext]{ref-lecun1998gradient}
\CSLLeftMargin{{[}1{]} }%
\CSLRightInline{Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner,
{``Gradient-based learning applied to document recognition,''}
\emph{Proceedings of the IEEE}, vol. 86, no. 11, pp. 2278--2324, 1998}

\bibitem[\citeproctext]{ref-rosenblatt1958perceptron}
\CSLLeftMargin{{[}2{]} }%
\CSLRightInline{F. Rosenblatt, {``The perceptron: A probabilistic model
for information storage and organization in the brain,''}
\emph{Psychological review}, vol. 65, p. 386, 1958}

\bibitem[\citeproctext]{ref-rumelhart1986learning}
\CSLLeftMargin{{[}3{]} }%
\CSLRightInline{D. E. Rumelhart, G. E. Hinton, and R. J. Williams,
{``Learning representations by back-propagating errors,''}
\emph{Nature}, vol. 323, no. 6088, pp. 533--536, 1986}

\bibitem[\citeproctext]{ref-zeiler2014visualizing}
\CSLLeftMargin{{[}4{]} }%
\CSLRightInline{M. D. Zeiler and R. Fergus, {``Visualizing and
understanding convolutional networks,''} \emph{European conference on
computer vision}, pp. 818--833, 2014}

\bibitem[\citeproctext]{ref-goodfellow2016deep}
\CSLLeftMargin{{[}5{]} }%
\CSLRightInline{I. Goodfellow, Y. Bengio, and A. Courville, \emph{Deep
learning}MIT press, 2016}

\end{CSLReferences}




\end{document}
