{
  "hash": "61920942c970ee8f9e014783cd629497",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"MNIST Dataset Exploration\"\nauthor: \"Data Science Team\"\nformat:\n  html:\n    code-fold: false\n    toc: true\n---\n\n\n\n\n# MNIST Dataset Exploration\n\nThis document explores the characteristics and statistics of the MNIST dataset. We will load the data and perform visual analysis.\n\n## Loading Data\n\nFirst, we need to import the necessary libraries and load the MNIST dataset.\n\n::: {#load-libraries .cell execution_count=1}\n``` {.python .cell-code}\nimport sys\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import datasets, transforms\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\n# Set matplotlib style\nplt.style.use('ggplot')\n```\n:::\n\n\n::: {#load-data .cell execution_count=2}\n``` {.python .cell-code}\n# Define data transformation\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\n# Load MNIST dataset\ndata_dir = '../data'\ntrain_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n\nprint(f\"Training set size: {len(train_dataset)} samples\")\nprint(f\"Test set size: {len(test_dataset)} samples\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining set size: 60000 samples\nTest set size: 10000 samples\n```\n:::\n:::\n\n\n## Data Visualization\n\n### Viewing Sample Images\n\nLet's visualize some MNIST image samples to understand the characteristics of the data.\n\n::: {#cell-visualize-samples .cell execution_count=3}\n``` {.python .cell-code}\n# Create a function to display images\ndef show_images(dataset, num_images=25, rows=5, cols=5):\n    # Create a new figure\n    plt.figure(figsize=(12, 12))\n    \n    # Randomly select images\n    indices = np.random.choice(len(dataset), num_images, replace=False)\n    \n    # Display images\n    for i, idx in enumerate(indices):\n        if i >= num_images:\n            break\n        \n        # Get image and label\n        img, label = dataset[idx]\n        img = img.squeeze().numpy()  # Convert to numpy and remove channel dimension\n        \n        # Create subplot\n        plt.subplot(rows, cols, i + 1)\n        plt.imshow(img, cmap='gray')\n        plt.title(f'Label: {label}')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Display some images from the training set\nshow_images(train_dataset)\n```\n\n::: {.cell-output .cell-output-display}\n![MNIST Dataset Sample Images](data-exploration_files/figure-html/visualize-samples-output-1.png){#visualize-samples width=1119 height=1142}\n:::\n:::\n\n\n### Label Distribution\n\nLet's look at the distribution of digits in the training and test sets.\n\n::: {#label-distribution .cell execution_count=4}\n``` {.python .cell-code}\n# Get all labels\ntrain_labels = [label for _, label in train_dataset]\ntest_labels = [label for _, label in test_dataset]\n\n# Calculate frequency of each digit\ndef plot_label_distribution(train_labels, test_labels):\n    train_counts = np.bincount(train_labels)\n    test_counts = np.bincount(test_labels)\n    \n    # Create dataframe\n    df = pd.DataFrame({\n        'Training Set': train_counts,\n        'Test Set': test_counts\n    }, index=range(10))\n    \n    # Create stacked bar chart\n    ax = df.plot(kind='bar', figsize=(12, 6), rot=0)\n    plt.title('Number of Samples for Each Digit in MNIST Dataset')\n    plt.xlabel('Digit')\n    plt.ylabel('Number of Samples')\n    plt.xticks(range(10), [str(i) for i in range(10)])\n    \n    # Add value labels to each bar\n    for container in ax.containers:\n        ax.bar_label(container, fmt='%d')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Return percentage distribution\n    train_pct = (train_counts / len(train_labels) * 100).round(2)\n    test_pct = (test_counts / len(test_labels) * 100).round(2)\n    \n    pct_df = pd.DataFrame({\n        'Training Set (%)': train_pct,\n        'Test Set (%)': test_pct\n    }, index=range(10))\n    \n    return pct_df\n\n# Plot label distribution and display percentage table\npct_table = plot_label_distribution(train_labels, test_labels)\npct_table\n```\n\n::: {.cell-output .cell-output-display}\n![Label Distribution in Training and Test Sets](data-exploration_files/figure-html/label-distribution-output-1.png){#label-distribution-1 width=1143 height=566}\n:::\n\n::: {#label-distribution-2 .cell-output .cell-output-display execution_count=36}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Training Set (%)</th>\n      <th>Test Set (%)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.87</td>\n      <td>9.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11.24</td>\n      <td>11.35</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.93</td>\n      <td>10.32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.22</td>\n      <td>10.10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.74</td>\n      <td>9.82</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9.04</td>\n      <td>8.92</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>9.86</td>\n      <td>9.58</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10.44</td>\n      <td>10.28</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.75</td>\n      <td>9.74</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9.92</td>\n      <td>10.09</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Pixel Intensity Distribution\n\nLet's analyze the pixel intensity distribution of MNIST images.\n\n::: {#cell-pixel-intensity .cell execution_count=5}\n``` {.python .cell-code}\n# Create a function to calculate pixel intensity statistics\ndef analyze_pixel_intensity(dataset, num_samples=1000):\n    # Randomly select samples\n    indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)\n    \n    # Collect images\n    images = []\n    for idx in indices:\n        img, _ = dataset[idx]\n        # Remove normalization to get original pixel values\n        img = img * 0.3081 + 0.1307  # De-normalize\n        images.append(img.squeeze().numpy())\n    \n    # Stack images into a large array\n    images_array = np.stack(images)\n    \n    # Calculate average pixel intensity for each image\n    mean_intensities = images_array.mean(axis=(1, 2))\n    \n    # Calculate overall mean intensity\n    overall_mean = images_array.mean()\n    overall_std = images_array.std()\n    \n    # Create histograms\n    plt.figure(figsize=(12, 6))\n    \n    # Mean intensity histogram\n    plt.subplot(1, 2, 1)\n    plt.hist(mean_intensities, bins=30, alpha=0.7, color='blue')\n    plt.axvline(overall_mean, color='red', linestyle='dashed', linewidth=2)\n    plt.title(f'Mean Pixel Intensity Distribution\\nMean: {overall_mean:.4f}')\n    plt.xlabel('Mean Pixel Intensity')\n    plt.ylabel('Number of Images')\n    \n    # All pixel intensities histogram\n    plt.subplot(1, 2, 2)\n    plt.hist(images_array.flatten(), bins=50, alpha=0.7, color='green')\n    plt.title(f'All Pixel Intensity Distribution\\nStandard Deviation: {overall_std:.4f}')\n    plt.xlabel('Pixel Intensity')\n    plt.ylabel('Frequency')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return overall_mean, overall_std\n\n# Analyze pixel intensity of training set\nmean_intensity, std_intensity = analyze_pixel_intensity(train_dataset)\nprint(f\"Mean pixel intensity: {mean_intensity:.4f}\")\nprint(f\"Pixel intensity standard deviation: {std_intensity:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n![MNIST Image Pixel Intensity Distribution](data-exploration_files/figure-html/pixel-intensity-output-1.png){#pixel-intensity width=1143 height=566}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nMean pixel intensity: 0.1312\nPixel intensity standard deviation: 0.3089\n```\n:::\n:::\n\n\n### Dimensionality Reduction Visualization\n\nUsing PCA and t-SNE to visualize MNIST data distribution in lower-dimensional space.\n\n::: {#cell-dimensionality-reduction .cell execution_count=6}\n``` {.python .cell-code}\n# Dimensionality reduction visualization function\ndef visualize_with_dimensionality_reduction(dataset, n_samples=2000):\n    # Randomly select samples\n    indices = np.random.choice(len(dataset), min(n_samples, len(dataset)), replace=False)\n    \n    # Collect data and labels\n    data = []\n    labels = []\n    for idx in indices:\n        img, label = dataset[idx]\n        data.append(img.squeeze().numpy().flatten())  # Flatten 28x28 to 784-dimensional vector\n        labels.append(label)\n    \n    # Convert to numpy arrays\n    X = np.array(data)\n    y = np.array(labels)\n    \n    # Use PCA to reduce to 2 dimensions\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X)\n    \n    # Use t-SNE to reduce to 2 dimensions\n    tsne = TSNE(n_components=2, random_state=42)\n    X_tsne = tsne.fit_transform(X)\n    \n    # Create figure\n    plt.figure(figsize=(16, 7))\n    \n    # PCA scatter plot\n    plt.subplot(1, 2, 1)\n    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', s=5, alpha=0.7)\n    plt.colorbar(scatter, label='Digit Label')\n    plt.title('PCA Dimensionality Reduction (2D)')\n    plt.xlabel(f'Principal Component 1 (Explained Variance: {pca.explained_variance_ratio_[0]:.4f})')\n    plt.ylabel(f'Principal Component 2 (Explained Variance: {pca.explained_variance_ratio_[1]:.4f})')\n    \n    # t-SNE scatter plot\n    plt.subplot(1, 2, 2)\n    scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', s=5, alpha=0.7)\n    plt.colorbar(scatter, label='Digit Label')\n    plt.title('t-SNE Dimensionality Reduction (2D)')\n    plt.xlabel('t-SNE Dimension 1')\n    plt.ylabel('t-SNE Dimension 2')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Return PCA variance explanation ratio\n    return pca.explained_variance_ratio_\n\n# Perform dimensionality reduction visualization on training set\nvar_ratio = visualize_with_dimensionality_reduction(train_dataset)\nprint(f\"Cumulative explained variance ratio of first 10 principal components in PCA: {np.sum(var_ratio):.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n![MNIST Data Visualization through PCA and t-SNE Dimensionality Reduction](data-exploration_files/figure-html/dimensionality-reduction-output-1.png){#dimensionality-reduction width=1490 height=662}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCumulative explained variance ratio of first 10 principal components in PCA: 0.1728\n```\n:::\n:::\n\n\n### Digit Feature Analysis\n\nDifferent digits have variations in shape and strokes. Let's analyze the average shape and variability of each digit.\n\n::: {#cell-digit-features .cell execution_count=7}\n``` {.python .cell-code}\n# Analyze average shape and variance of each digit\ndef analyze_digit_features(dataset):\n    # Create a dictionary to store all images for each digit\n    digit_images = {i: [] for i in range(10)}\n    \n    # Collect images for each digit\n    for idx in range(len(dataset)):\n        img, label = dataset[idx]\n        img = img.squeeze().numpy()\n        digit_images[label].append(img)\n    \n    # Calculate average image and variance for each digit\n    mean_images = {}\n    var_images = {}\n    for digit, images in digit_images.items():\n        images_array = np.stack(images)\n        mean_images[digit] = np.mean(images_array, axis=0)\n        var_images[digit] = np.var(images_array, axis=0)\n    \n    # Create figure to display average image and variance for each digit\n    plt.figure(figsize=(15, 6))\n    \n    # Display average images\n    plt.subplot(1, 2, 1)\n    # Create a 3x4 grid to display all digits\n    grid_img = np.zeros((28*3, 28*4))\n    \n    for i, digit in enumerate(range(10)):\n        row, col = i // 4, i % 4\n        grid_img[row*28:(row+1)*28, col*28:(col+1)*28] = mean_images[digit]\n    \n    plt.imshow(grid_img, cmap='viridis')\n    plt.title('Average Shape of Each Digit')\n    plt.axis('off')\n    \n    # Display variance images\n    plt.subplot(1, 2, 2)\n    # Create a 3x4 grid to display variance for all digits\n    grid_var = np.zeros((28*3, 28*4))\n    \n    for i, digit in enumerate(range(10)):\n        row, col = i // 4, i % 4\n        grid_var[row*28:(row+1)*28, col*28:(col+1)*28] = var_images[digit]\n    \n    plt.imshow(grid_var, cmap='plasma')\n    plt.title('Pixel Variance of Each Digit')\n    plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return mean_images, var_images\n\n# Analyze digit features\nmean_imgs, var_imgs = analyze_digit_features(train_dataset)\n```\n\n::: {.cell-output .cell-output-display}\n![Average Shape and Variance of Each Digit](data-exploration_files/figure-html/digit-features-output-1.png){#digit-features width=1430 height=566}\n:::\n:::\n\n\n## Feature Correlation Analysis\n\nAnalyze similarities and differences between different digits.\n\n::: {#cell-feature-correlation .cell execution_count=8}\n``` {.python .cell-code}\n# Calculate similarity between digits\ndef compute_digit_similarities(mean_images):\n    # Calculate 10x10 similarity matrix\n    similarity_matrix = np.zeros((10, 10))\n    \n    # Flatten average images\n    flattened_means = {digit: img.flatten() for digit, img in mean_images.items()}\n    \n    # Calculate correlation coefficient between each pair of digits\n    for i in range(10):\n        for j in range(10):\n            similarity_matrix[i, j] = np.corrcoef(flattened_means[i], flattened_means[j])[0, 1]\n    \n    # Plot heatmap\n    plt.figure(figsize=(10, 8))\n    plt.imshow(similarity_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n    plt.colorbar(label='Correlation Coefficient')\n    plt.title('Similarity Matrix Between Digits')\n    plt.xlabel('Digit')\n    plt.ylabel('Digit')\n    plt.xticks(range(10))\n    plt.yticks(range(10))\n    \n    # Add correlation coefficient text\n    for i in range(10):\n        for j in range(10):\n            plt.text(j, i, f'{similarity_matrix[i, j]:.2f}', \n                    ha='center', va='center', \n                    color='white' if abs(similarity_matrix[i, j]) > 0.5 else 'black')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return similarity_matrix\n\n# Calculate digit similarity\nsim_matrix = compute_digit_similarities(mean_imgs)\n```\n\n::: {.cell-output .cell-output-display}\n![Similarity Matrix Between Digits](data-exploration_files/figure-html/feature-correlation-output-1.png){#feature-correlation width=880 height=758}\n:::\n:::\n\n\n## Conclusion\n\nFrom the above analysis, we can draw the following conclusions about the MNIST dataset:\n\n1. The MNIST dataset is well-balanced, with similar distributions of digits in both training and test sets\n2. The pixel intensity distribution shows the characteristics of handwritten digits, with most pixels being background (low intensity)\n3. Dimensionality reduction analysis indicates that different digits form distinct clusters in feature space\n4. Some digits (such as 1 and 7) have higher similarity, while others (such as 0 and 1) have greater differences\n5. The average images clearly show the typical shape of each digit \n\n",
    "supporting": [
      "data-exploration_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}